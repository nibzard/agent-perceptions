**Major Weaknesses and Concerns:**

1.  **Survey Instrument and Distribution Details:** The manuscript lacks crucial details about the survey instrument's development (e.g., pre-testing, validation of questions/constructs) and distribution methodology. Simply stating it was distributed "online during April-May 2025" and targeted "likely" professionals is insufficient for rigorous scientific reporting. How were participants recruited? What platforms were used? This information is essential for evaluating potential sampling biases beyond the likely tech focus.
2.  **Inconsistency and Clarity of Clustering Results:** This is a critical issue. Section 3.3 describes three clusters ("Pragmatic Adopters," "Cautious Regulators," "Uncertain Observers") with specific characteristics. However, Supplementary Table S1, which supposedly provides the modal answers defining these clusters, appears significantly inconsistent with the textual descriptions. For example:
    *   Cluster 0 (described as "Pragmatic Adopters" deploying agents and favoring shared responsibility) has modal answers in Table S1 like Q3="We ARE deploying them now" (consistent) but Q4="All decisions need human approval (defeating the purpose)" (highly inconsistent with shared responsibility or pragmatism) and Q5="Self-modification of their own architecture" (seems more advanced/risky than pragmatic).
    *   Cluster 1 (described as "Cautious Regulators" emphasizing concerns) has "No opinion" as the modal answer for many key questions (Q2, Q5, Q6, Q7, Q8, Q9, Q10) in Table S1, making the "Cautious Regulator" label difficult to justify based solely on modal responses. This profile looks more like the "Uncertain Observers".
    *   Cluster 2 (described as "Uncertain Observers") has modal answers in Table S1 like Q3="Regulatory/compliance..." (fits "Cautious Regulator"), Q4="The company deploying the agents" (specific responsibility view), Q5="Self-modification..." (similar to Cluster 0), Q10="Provide oversight..." (specific future role). This profile seems more aligned with the "Cautious Regulator" description.
    *   *Action Required:* The authors MUST reconcile the cluster descriptions in the main text with the data presented in Supplementary Table S1. Either the table is incorrect, the cluster interpretation/labeling is flawed, or the textual description misrepresents the modal profiles. This discrepancy undermines the credibility of a major finding. The justification for k=3 also relies partly on interpretability, which is compromised by this inconsistency.
3.  **MCA Inertia:** The manuscript notes that the first two MCA dimensions explained approximately 20% of the total inertia. This is quite low, suggesting that a large portion of the variance in responses is not captured by these two dimensions. While common in survey data with many categorical variables, this limitation should be explicitly discussed, particularly regarding how well the subsequent clustering (based on MCA results, though K-Modes works on original data) truly represents the underlying structure.

**Minor Issues and Suggestions:**

1.  **Methods - Logistic Regression Predictors:** Briefly clarify why Q3 response options (barriers) *other than* "Regulatory/compliance concerns" were or were not included as predictors for current deployment status ("We ARE deploying them now"). It seems counterintuitive not to test if "Fear of the unknown" or "Leadership doesn't understand" also predict *non*-deployment. (It appears "Regulatory/compliance..." *was* included, based on Sec 3.4, but the methods description was slightly ambiguous).
2.  **Results - Qualitative Data:** While appropriately cautious about the small N=11 for Q11, providing one or two illustrative (anonymized) quotes for the key themes identified in Section 3.5 would strengthen this section.
3.  **Discussion - Limitations:** Add a point acknowledging potential limitations related to the survey instrument itself (e.g., specific wording, fixed choice options potentially missing nuances).